{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import flammkuchen as fl\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from lavian_et_al_2025.imaging.imaging_classes import TwoPExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_decay_kernel(tau, dt, len_rec):\n",
    "    upsample = 10\n",
    "    t = np.arange(len_rec * upsample) * dt / upsample\n",
    "    \n",
    "    decay = np.exp(-t / tau)\n",
    "    decay /= np.sum(decay)\n",
    "    return decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc7bd7-5a71-4988-9108-f5c5a541218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_square(square_size, radius, proj_height):\n",
    "    circumf = 2*np.pi*radius\n",
    "    scale_factor = circumf / proj_height\n",
    "    scaled_size = square_size * scale_factor\n",
    "    return scaled_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-declaration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to the dataset\n",
    "master = Path(r\"\")\n",
    "files = list(master.glob(\"*_f*\"))\n",
    "\n",
    "# choose a fish\n",
    "fish = files[0]\n",
    "\n",
    "# choose a plane \n",
    "path = fish / 'suite2p' / '0001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading suite2p data:\n",
    "suite2p_data = fl.load(path / 'data_from_suite2p_unfiltered.h5')\n",
    "coords = suite2p_data[\"coords\"]\n",
    "anat = suite2p_data[\"anatomy_stack\"]\n",
    "traces = suite2p_data[\"traces\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing traces:\n",
    "traces = traces.T\n",
    "traces = ((traces - traces.mean(0)) / traces.std(0))\n",
    "traces = traces.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting stimulus information\n",
    "metadata_file = list(path.glob(\"*_metadata.json\"))[0]\n",
    "\n",
    "with open(str(metadata_file), \"r\") as f:\n",
    "     metadata = json.load(f)\n",
    "        \n",
    "stim = metadata[\"stimulus\"][\"log\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping stimulus position to the way it is saved in the metadata file\n",
    "num_rows = 8\n",
    "n_regs = num_rows\n",
    "s_size = 1 / num_rows\n",
    "s_size = 0.5 / num_rows\n",
    "radius = 0.3\n",
    "proj_height = [2, 1.75, 1.5, 1.25, 1.25, 1.5, 1.75, 2]\n",
    "        \n",
    "choices = []\n",
    "for x_pos in range(num_rows):\n",
    "    scaled_size = scale_square(s_size, radius, proj_height[x_pos])\n",
    "    curr_choice = [0, x_pos / num_rows, 1, scaled_size]\n",
    "    choices.append(curr_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-persian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting tail information:\n",
    "beh_file = list(path.glob(\"*_behavior*\"))[0]\n",
    "beh_log = fl.load(beh_file)['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting stimulus timing parameters \n",
    "fs = int(metadata['imaging']['microscope_config']['scanning']['framerate'])\n",
    "pause_duration = stim[0]['duration'] * fs\n",
    "stim_duration = stim[1]['duration'] * fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding trial start and end times\n",
    "n_options = 8\n",
    "n_rep = [metadata['stimulus']['protocol']['receptive_fields']['v06_front_cols_flashes_1x8']['n_trials']][0]\n",
    "n_trials = (n_options * n_rep) \n",
    "position_list = np.zeros((n_trials, 4))\n",
    "for_regs = np.zeros((n_options, n_trials * 2 + 1))\n",
    "\n",
    "len_rec = np.shape(traces)[1]\n",
    "regs = np.zeros((n_options, len_rec))\n",
    "t1 = pause_duration\n",
    "\n",
    "for i in range(1, n_trials * 2, 2):\n",
    "    curr_trial = stim[i]['clip_mask']\n",
    "    position_list[(i//2) - 1, :] = curr_trial\n",
    "    \n",
    "    for j in range(n_options):\n",
    "        if curr_trial == choices[j]:\n",
    "            for_regs[j, i-1] = 1\n",
    "            regs[j, t1:(t1 + stim_duration)] = 1\n",
    "    \n",
    "    t1 = t1 + stim_duration + pause_duration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating regressors \n",
    "from lotr.default_vals import REGRESSOR_TAU_S, TURN_BIAS\n",
    "\n",
    "dt_imaging = 1 / fs\n",
    "int_fact = 200\n",
    "t_imaging = np.arange(traces.shape[1])/fs\n",
    "num_traces, len_rec = np.shape(traces)\n",
    "\n",
    "tau_fs = REGRESSOR_TAU_S * fs\n",
    "kernel = np.exp(-np.arange(1000) / tau_fs)\n",
    "t_imaging_int = np.arange(traces.shape[1]*int_fact)*dt_imaging/int_fact\n",
    "\n",
    "regs_conv = np.zeros((n_options, len_rec))\n",
    "regs_vals = np.zeros((n_options, num_traces))\n",
    "\n",
    "for i in range(n_options):\n",
    "    regs_conv[i] = np.convolve(regs[i], kernel)[:np.shape(traces)[1]]\n",
    "    \n",
    "    tmp_reg_vals = np.dot(traces, regs_conv[i]) - num_traces * np.mean(traces, 1) * np.mean(regs_conv[i])\n",
    "    tmp_reg_vals /= (traces.shape[1] - 1) * np.std(traces, 1) * np.std(regs_conv[i])\n",
    "    regs_vals[i] = tmp_reg_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the different regressors, tail trace and neural traces\n",
    "fig_regs, ax_regs = plt.subplots(2, 1, figsize=(8, 6))\n",
    "\n",
    "for i in range(n_options):\n",
    "    ax_regs[0].plot(regs_conv[i] + (i * 20))\n",
    "\n",
    "ax_regs[0].plot(beh_log.t * fs, beh_log.tail_sum*10 - 80, c='k')\n",
    "\n",
    "ax_regs[0].set_xlim(0, len_rec)    \n",
    "ax_regs[0].axis('off')\n",
    "ax_regs[1].axis('off')\n",
    "ax_regs[1].imshow(traces, extent=[0, 1500, 0, 500], cmap='coolwarm', vmin=-2, vmax=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07dbe1-d81f-4b50-afdb-477c89cbd928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the habenula in order to only analyze habenula traces in following sections\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(anat.mean(0), vmax=1000, vmin=0, cmap='gray_r')\n",
    "plt.scatter(coords[:, 2], coords[:, 1], c=(0.9,)*3, s=1)\n",
    "s1 = 20\n",
    "s2 = 330\n",
    "plt.axhline(s1)\n",
    "plt.axhline(s2)\n",
    "\n",
    "s3 = 140\n",
    "s4 = 240\n",
    "plt.axvline(s3)\n",
    "plt.axvline(s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21707f31-a9ab-449c-9fa5-b5a9eea79edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing ROIs not from of the habenula\n",
    "sel_to_nan = (coords[:, 1] < s1) | (coords[:, 1] > s2) | (coords[:, 2] < s3) | (coords[:, 2] > s4)\n",
    "traces[sel_to_nan] = 0\n",
    "\n",
    "regs_vals_new = np.copy(regs_vals)\n",
    "regs_vals_new[:, sel_to_nan] = 0\n",
    "\n",
    "new_coords = coords[sel_to_nan]\n",
    "plt.scatter(new_coords[:, 2], new_coords[:, 1], c=(0.5,)*3, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_row = 2\n",
    "num_col = 4\n",
    "fig_rf_reg1, ax_rf_reg1 = plt.subplots(num_row, num_col, figsize=(10, 5), sharex=True, sharey=True)\n",
    "\n",
    "for i in range(n_options):\n",
    "    r = i // num_col\n",
    "    c = np.mod(i, num_col)\n",
    "    ax_rf_reg1[r,c].invert_yaxis()\n",
    "    \n",
    "    try:\n",
    "        ax_rf_reg1[r,c].scatter(coords[:, 1], coords[:, 2], c=regs_vals_new[i], cmap='coolwarm', s=2, vmin=-0.7, vmax=0.7)\n",
    "        ax_rf_reg1[r,c].set_title(title_list[i], fontsize=15)\n",
    "    except:\n",
    "        print(\"no plane\")\n",
    "    ax_rf_reg1[r,c].axis('off')\n",
    "    \n",
    "plt.subplots_adjust(hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_regs2, ax_regs2 = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "for i in range(n_options):\n",
    "    ax_regs2.plot(regs_conv[i] + (i * 20), c='royalblue')\n",
    "    \n",
    "    max_corr = np.nanmax(regs_vals_new[i])\n",
    "    max_ind = np.argmax(regs_vals_new[i])\n",
    "    \n",
    "    ax_regs2.plot(traces[max_ind] + (i * 20), c='skyblue')\n",
    "\n",
    "ax_regs2.set_xlim(0, len_rec)    \n",
    "ax_regs2.axis('off')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_row = 8\n",
    "fig_regs4, ax_regs4 = plt.subplots(num_row, 8, figsize=(8, 6), sharex=True, sharey=True)\n",
    "\n",
    "for rf in range(num_row):\n",
    "    \n",
    "    ax_regs4[0, rf].set_title(title_list[rf], fontsize=10)\n",
    "    max_ind = np.argmax(regs_vals_new[rf])\n",
    "    trace = traces[max_ind]\n",
    "    \n",
    "    for i in range(n_options):\n",
    "        trial_trace = np.zeros((n_rep, 50))\n",
    "\n",
    "        reg_dif = np.diff(regs[i])\n",
    "        t_start = np.where(reg_dif > 0)[0] - 10\n",
    "        t_end = t_start + 50\n",
    "        t_vec = (np.arange(50) - 10 )/ fs\n",
    "\n",
    "        for trial in range(n_rep):\n",
    "            try:\n",
    "                trial_trace[trial] = trace[t_start[trial]:t_end[trial]]\n",
    "            except:\n",
    "                print(\"Error\")\n",
    "\n",
    "        trace_avg = np.nanmean(trial_trace, axis=0)\n",
    "        trace_sem = np.nanstd(trial_trace, axis=0)/np.sqrt(n_rep)\n",
    "        ax_regs4[rf, i].plot(t_vec,  trace_avg, c='royalblue')\n",
    "        ax_regs4[rf, i].fill_between(t_vec, trace_avg - trace_sem, trace_avg + trace_sem, color='lightblue')\n",
    "\n",
    "        if i is not 0 or rf < 7:\n",
    "            ax_regs4[rf, i].axis('off')\n",
    "        else:\n",
    "            ax_regs4[rf, i].spines['right'].set_visible(False)\n",
    "            ax_regs4[rf, i].spines['top'].set_visible(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
