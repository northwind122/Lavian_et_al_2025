{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91bd1d5-6c15-4176-b18d-2ee39aafec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5189126b-bd24-4fe9-acf2-4c15edb2b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import flammkuchen as fl\n",
    "from split_dataset import SplitDataset\n",
    "from bouter import Experiment\n",
    "from fimpy.pipeline.general import calc_f0, dff\n",
    "from motions.utilities import stim_vel_dir_dataframe, quantize_directions\n",
    "from scipy.interpolate import interp1d \n",
    "from scipy.signal import convolve2d\n",
    "import colorspacious\n",
    "import napari\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from fimpylab.core.twop_experiment import TwoPExperiment\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "from pathlib import Path\n",
    "import tifffile as tiff\n",
    "\n",
    "from general_analysis.helper_functions_imaging.general_imaging import normalize_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd9a024-4d83-4d3d-83c0-789697b68d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sensory regressors. requires old bouter stimulus_param_log.\n",
    "def make_sensory_regressors(exp, n_dirs=8, upsampling=5, sampling=1/3):\n",
    "    stim = stim_vel_dir_dataframe(exp)\n",
    "    bin_centres, dir_bins = quantize_directions(stim.theta)\n",
    "    ind_regs = np.zeros((n_dirs, len(stim)))\n",
    "    for i_dir in range(n_dirs):\n",
    "        ind_regs[i_dir, :] = (np.abs(dir_bins - i_dir) < 0.1) & (stim.vel > 0.1)  \n",
    "\n",
    "    dt_upsampled = sampling / upsampling\n",
    "    t_imaging_up = np.arange(0, stim.t.values[-1], dt_upsampled)\n",
    "    reg_up = interp1d(stim.t.values, ind_regs, axis=1, fill_value=\"extrapolate\")(\n",
    "        t_imaging_up\n",
    "    )\n",
    "    \n",
    "    # 6s kernel\n",
    "    u_steps = t_imaging_up.shape[0]\n",
    "    u_time = np.arange(u_steps) * dt_upsampled\n",
    "    decay = np.exp(-u_time / (1.5 / np.log(2)))\n",
    "    kernel = decay / np.sum(decay)\n",
    "    \n",
    "    convolved = convolve2d(reg_up, kernel[None, :])[:, 0:u_steps]\n",
    "    reg_sensory = convolved[:, ::upsampling]\n",
    "\n",
    "    return pd.DataFrame(reg_sensory.T, columns=[f\"motion_{i}\" for i in range(n_dirs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3484780-0bab-4852-a62a-a8181a528c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate directional tuning from dF/F traces, px-wise\n",
    "def get_tuning_map(traces, sens_regs, n_dirs=8):\n",
    "\n",
    "    n_t = sens_regs.shape[0]\n",
    "    reg = sens_regs.T @ traces[:n_t, :]\n",
    "    #print(np.shape(reg))\n",
    "    #reg = reg.reshape(reg.shape[0], traces.shape[-1], traces.shape[-1])\n",
    "    \n",
    "    # tuning vector\n",
    "    bin_centers, bins = quantize_directions([0], n_dirs)\n",
    "    vectors = np.stack([np.cos(bin_centers), np.sin(bin_centers)], 0)\n",
    "    #print(np.shape(vectors))\n",
    "    reg_vectors = vectors @ reg\n",
    "    #print(np.shape(reg_vectors))\n",
    "\n",
    "    angle = np.arctan2(reg_vectors[1], reg_vectors[0])\n",
    "    amp = np.sqrt(np.sum(reg_vectors ** 2, 0))\n",
    "\n",
    "    return amp, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f65268-c5ba-4c29-8bc1-048f5af94e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a color map\n",
    "\n",
    "def JCh_to_RGB255(x):\n",
    "    output = np.clip(colorspacious.cspace_convert(x, \"JCh\", \"sRGB1\"), 0, 1)\n",
    "    return (output * 255).astype(np.uint8)\n",
    "\n",
    "def color_stack(\n",
    "        amp,\n",
    "        angle,\n",
    "        hueshift=2.5,\n",
    "        amp_percentile=80,\n",
    "        maxsat=50,\n",
    "        lightness_min=100,\n",
    "        lightness_delta=-40,\n",
    "    ):\n",
    "    output_lch = np.zeros((amp.shape[0], 3))\n",
    "    print(np.shape(output_lch))\n",
    "    output_lch[:,0]\n",
    "    maxamp = np.percentile(amp, amp_percentile)\n",
    "\n",
    "    output_lch[:, 0] = (\n",
    "            lightness_min + (np.clip(amp / maxamp, 0, 1)) * lightness_delta\n",
    "    )\n",
    "    output_lch[:, 1] = (np.clip(amp / maxamp, 0, 1)) * maxsat\n",
    "    output_lch[:, 2] = (angle + hueshift) * 180 / np.pi\n",
    "\n",
    "    return JCh_to_RGB255(output_lch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3307115-cb5c-4f7d-95fa-8fd64dfe6b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "master = Path(r\"Z:\\Hagar and Ot\\e0075\\ipn h2b\")\n",
    "\n",
    "fish_list = list(master.glob(\"*_f*\"))\n",
    "fish = fish_list[1]\n",
    "print(fish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ea8c7-cf63-445e-a567-8e98cfc9f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "anatomy = fl.load(fish / 'registration' / 'ref_mapped.h5').T\n",
    "#anatomy = fl.load(fish / 'registration' / 'mov_mapped.h5').T\n",
    "\n",
    "\n",
    "fish_path = fish / 'suite2p'\n",
    "paths = list(fish_path.glob(\"*00*\"))\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4835afa1-ce90-42bf-a7d0-72ba486a63a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_exp = TwoPExperiment(fish)\n",
    "fs = img_exp['imaging']['microscope_config']['scanning']['framerate']\n",
    "sampling = 1/fs\n",
    "res = img_exp.resolution\n",
    "z_res, x_res, y_res = img_exp.resolution\n",
    "\n",
    "thresh = 0.3\n",
    "\n",
    "print(z_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c10b56-97d9-4127-aae9-10569994d643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c0b67-50a1-4aab-bf97-d5ade91706d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_count = 0\n",
    "\n",
    "coords = fl.load(fish / 'registration' / 'ref_roi_coords_mapped.h5')\n",
    "#coords = fl.load(fish / 'registration' / 'mov_coords_transformed.h5')\n",
    "\n",
    "count=0\n",
    "for path in paths:\n",
    "    ### concatenate reliability index for all fish\n",
    "    rel_index = fl.load(path / 'reliability_index_arr.h5')['reliability_arr_combined']\n",
    "\n",
    "    ### concatenate all regression values for all cells for all fish\n",
    "    traces = fl.load(path / \"filtered_traces.h5\", \"/detr\")\n",
    "\n",
    "    # make a list of sensory regressors \n",
    "    try:\n",
    "        sensory_regressors = fl.load(path / \"sensory_regressors.h5\", \"/regressors_conv\")\n",
    "    except:\n",
    "        sensory_regressors = fl.load(path / \"sensory_regressors_cells.h5\", \"/regressors_conv\")\n",
    "    reg_list = [sensory_regressors]\n",
    "    n_t = sensory_regressors.shape[0]\n",
    "\n",
    "    # calculate tuning\n",
    "    amp, angle = get_tuning_map(traces, sensory_regressors.T)\n",
    "\n",
    "    if count is 0:\n",
    "        all_reliability = rel_index\n",
    "        all_amp = amp\n",
    "        all_angle = angle\n",
    "    else:\n",
    "        all_reliability = np.append(all_reliability, rel_index)\n",
    "        all_amp = np.append(all_amp, amp)\n",
    "        all_angle = np.append(all_angle, angle)\n",
    "    count += 1\n",
    "\n",
    "\n",
    "\n",
    "thresh = threshold_otsu(all_reliability)\n",
    "print(\"Reliability threshold: \", thresh)\n",
    "thresh = 0.15\n",
    "\n",
    "colors = color_stack(all_amp, all_angle)\n",
    "amp_thresh = np.copy(all_amp)\n",
    "amp_thresh[np.where(all_amp < thresh)[0]] *= 0\n",
    "\n",
    "colors_thresh = np.copy(colors)\n",
    "colors_thresh[np.where(all_amp < thresh)[0]] *= 0\n",
    "colors_thresh[np.where(all_amp < thresh)[0]] += 220\n",
    "\n",
    "\n",
    "selected_vis = np.where(all_reliability > thresh)[0]\n",
    "coords_vis = coords[selected_vis]\n",
    "colors_vis = coords[selected_vis]\n",
    "colors_thresh = colors_thresh[selected_vis]\n",
    "amp_vis = all_amp[selected_vis]\n",
    "\n",
    "\n",
    "mp_ind = np.argsort(amp_vis)\n",
    "\n",
    "ind_count += 1\n",
    "\n",
    "#axs2.scatter(coords_vis[mp_ind,1]*y_res, coords_vis[mp_ind,2]*x_res, c=colors_thresh[mp_ind]/255, s=5, alpha=0.8)\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a6a78f-106e-4873-9ed8-1b5befd22089",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, axs2 = plt.subplots(1, 1, figsize=(3, 3))\n",
    "axs2.spines['right'].set_visible(False)\n",
    "axs2.spines['top'].set_visible(False)\n",
    "axs2.imshow(np.rot90(np.nanmean(anatomy, axis=0), 3), cmap='gray_r')\n",
    "axs2.scatter(coords_vis[mp_ind,1], coords_vis[mp_ind,0], c=colors_thresh[mp_ind]/255, s=10)\n",
    "axs2.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62552f6b-ca5a-49d9-9e4b-946cff5dfa8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6082369d-533d-4952-a320-b260f9b56e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(all_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a827fd6e-290f-4883-8652-c4dba8b19be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(all_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58819e4a-88bc-4d63-b0f1-f08cb10f2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d4dfdc-9427-47d6-875e-2c17df6a3304",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'coords': coords,\n",
    "    'amplitude': all_amp,\n",
    "    'angle': all_angle\n",
    "    }\n",
    "\n",
    "fl.save(fish / 'coords_amp_angle.h5', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a69ed-3296-43db-8a60-a68436e7a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"morphed tuning thresh stack \" + str(thresh) + \".jpg\"\n",
    "fig2.savefig(fish / file_name, dpi=300)\n",
    "file_name = \"morphed tuning thresh stack \" + str(thresh) + \".pdf\"\n",
    "fig2.savefig(fish / file_name, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5584f5dc-b4b8-4368-8085-d7079212cfad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ad8d73-f8e6-43c5-b744-ec17f5c1020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(all_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26bdf73-48c0-4143-a438-1ef5a05b6f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b02de-3a3e-4694-b1ad-4fdc774c4fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e579ad47-fe5f-4c7d-80d1-40fc54191aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
