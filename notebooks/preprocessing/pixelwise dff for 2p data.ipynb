{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275924a0-2ee0-45cd-9562-b44f54beaeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a964f75-329b-4742-a19b-5405fe5d79ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import flammkuchen as fl\n",
    "import json\n",
    "\n",
    "from split_dataset import SplitDataset\n",
    "%autoreload\n",
    "from glob import glob\n",
    "from bouter import Experiment\n",
    "\n",
    "from lavian_et_al_2025.visual_motion.stimulus_functions import stim_vel_dir_dataframe, quantize_directions\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import convolve2d\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6693c41c-1b35-4bea-a8f6-23806826acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import warnings\n",
    "from typing import List, Union, Tuple\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baddb77-8478-4bfe-abb6-59687d47dc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sensory_regressors(exp, n_dirs=8, upsampling=5, sampling=1/3):\n",
    "    stim = stim_vel_dir_dataframe(exp)\n",
    "    bin_centres, dir_bins = quantize_directions(stim.theta)\n",
    "    ind_regs = np.zeros((n_dirs, len(stim)))\n",
    "    for i_dir in range(n_dirs):\n",
    "        ind_regs[i_dir, :] = (np.abs(dir_bins - i_dir) < 0.1) & (stim.vel > 0.1)  \n",
    "\n",
    "    dt_upsampled = sampling / upsampling\n",
    "        \n",
    "    t_imaging_up = np.arange(0, stim.t.values[-1], dt_upsampled)\n",
    "    reg_up = interp1d(stim.t.values, ind_regs, axis=1, fill_value=\"extrapolate\")(\n",
    "        t_imaging_up\n",
    "    )\n",
    "    \n",
    "    # 6s kernel\n",
    "    u_steps = t_imaging_up.shape[0]\n",
    "    print(stim.t.values[-1])\n",
    "    u_time = np.arange(u_steps) * dt_upsampled\n",
    "    decay = np.exp(-u_time / (1.5 / np.log(2)))\n",
    "    kernel = decay / np.sum(decay)\n",
    "    \n",
    "    convolved = convolve2d(reg_up, kernel[None, :])[:, 0:u_steps]\n",
    "    reg_sensory = convolved[:, ::upsampling]\n",
    "\n",
    "    return pd.DataFrame(reg_sensory.T, columns=[f\"motion_{i}\" for i in range(n_dirs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a3992-6df3-420b-b938-c071e7d91340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dff(\n",
    "    stack: np.ndarray,\n",
    "    baseline_frames,\n",
    "    min_baseline_value: float = 1.0,\n",
    "    percentile_value: float = 1.0,\n",
    "    global_offset: float = None,\n",
    "    timing: bool = True\n",
    ") \n",
    "    \"\"\"\n",
    "    Calculate ΔF/F for a 4D calcium imaging stack with offset correction.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    stack : np.ndarray\n",
    "        4D array with dimensions (time, z, x, y)\n",
    "    baseline_frames : Union[List[int], np.ndarray, List[List[int]]]\n",
    "        Frame indices for baseline calculation.\n",
    "        If per_plane_baselines=True, should be a list with baseline frames for each z-plane.\n",
    "    min_baseline_value : float, optional\n",
    "        Minimum value for the baseline, by default 1.0\n",
    "    percentile_value : float, optional\n",
    "        Percentile to use for 'min_subtract' method (1.0 = 1st percentile), by default 1.0\n",
    "    global_offset : float, optional\n",
    "        Manual offset value to add if offset_correction='manual', by default None\n",
    "        Whether to handle NaN values in the data, by default True\n",
    "    timing : bool, optional\n",
    "        Whether to print timing information, by default True\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        4D array with ΔF/F values\n",
    "    \"\"\"\n",
    "    if timing:\n",
    "        start_time = time.time()\n",
    "    \n",
    "    # Convert to float if needed\n",
    "    if not np.issubdtype(stack.dtype, np.floating):\n",
    "        stack = stack.astype(np.float32)\n",
    "        if timing:\n",
    "            print(f\"Data type conversion: {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    # Get dimensions\n",
    "    t_max, z_max, x_max, y_max = stack.shape\n",
    "    \n",
    "    # Create a mask for NaN values in the original stack (to preserve them)\n",
    "    original_nan_mask = np.isnan(stack)\n",
    "    if timing and np.any(original_nan_mask):\n",
    "        print(f\"NaN values detected in input: {np.sum(original_nan_mask)} out of {stack.size} elements\")\n",
    "    \n",
    "    # Apply offset correction\n",
    "    if timing:\n",
    "        offset_start = time.time()\n",
    "    \n",
    "    # Create a copy to avoid modifying the original\n",
    "    # Replace NaNs with zeros for calculation purposes\n",
    "    corrected_stack = np.nan_to_num(stack, nan=0.0)\n",
    "    \n",
    "    # For each z-plane, find minimum (or low percentile) value and subtract\n",
    "    for z in range(z_max):\n",
    "        if handle_nans:\n",
    "            # Use nanpercentile to ignore NaNs when calculating percentile\n",
    "            min_value = np.nanpercentile(stack[:, z, :, :], percentile_value)\n",
    "        else:\n",
    "            # Use regular percentile\n",
    "            min_value = np.percentile(stack[:, z, :, :], percentile_value)\n",
    "\n",
    "        corrected_stack[:, z, :, :] -= min_value\n",
    "        if timing:\n",
    "            print(f\"Z-plane {z}: Subtracted {min_value:.2f} (percentile {percentile_value})\")\n",
    "\n",
    "    \n",
    "    if timing:\n",
    "        print(f\"Offset correction: {time.time() - offset_start:.2f} seconds\")\n",
    "        baseline_start = time.time()\n",
    "    \n",
    "    # Initialize result array\n",
    "    dff = np.zeros_like(corrected_stack)\n",
    "    \n",
    "    # Calculate ΔF/F with corrected stack\n",
    "    # Process each z-plane with its own baseline frames\n",
    "    for z in range(z_max):\n",
    "        # Get baseline frames for this plane\n",
    "        plane_frames = np.array(baseline_frames[z], dtype=int).flatten()\n",
    "\n",
    "        # Calculate baseline for this plane\n",
    "        if handle_nans:\n",
    "            # Use nanmean to ignore NaNs when calculating baseline\n",
    "            f0_plane = np.nanmean(stack[plane_frames, z, :, :], axis=0)\n",
    "            # Replace any remaining NaNs in baseline with min_baseline_value\n",
    "            f0_plane = np.nan_to_num(f0_plane, nan=min_baseline_value)\n",
    "        else:\n",
    "            f0_plane = np.mean(corrected_stack[plane_frames, z, :, :], axis=0)\n",
    "\n",
    "        # Apply minimum threshold\n",
    "        f0_plane = np.maximum(f0_plane, min_baseline_value)\n",
    "\n",
    "        # Calculate ΔF/F for this plane\n",
    "        dff[:, z, :, :] = (corrected_stack[:, z, :, :] - f0_plane) / f0_plane\n",
    "\n",
    "    \n",
    "    # Restore original NaN values\n",
    "    if np.any(original_nan_mask):\n",
    "        dff[original_nan_mask] = np.nan\n",
    "    \n",
    "    if timing:\n",
    "        total_time = time.time() - start_time\n",
    "        baseline_time = time.time() - baseline_start\n",
    "        print(f\"Baseline calculation: {baseline_time:.2f} seconds\")\n",
    "        print(f\"Total ΔF/F calculation: {total_time:.2f} seconds\")\n",
    "    \n",
    "    return dff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc243bc-9637-4a16-9975-414d02e2823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the frames to calculate the baseline.\n",
    "def no_regressor_frames(regressors, threshold=0.05):\n",
    "    return np.where(np.all(regressors < threshold, axis=0))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14570cf6-3bce-4ab8-96f6-4cc04ffb72c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "master = Path(r\"\\\\Funes2\\data\\Hagar and Ot\\E0040\\v10\\2p\\s1186t\")\n",
    "\n",
    "all_fish = list(master.glob(\"*_f*\"))\n",
    "fish_dir = all_fish[-1]\n",
    "print(all_fish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bda07d6-a618-4a61-8233-7c3bb5cc6212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ea42d-b96f-4ade-8f61-9db6796800c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in all_fish[:]:\n",
    "    print(f)\n",
    "    #try:\n",
    "    if not (f / \"dff2\").exists():\n",
    "        \n",
    "        stack = SplitDataset(f / \"aligned\")[:,:,:,:]\n",
    "        len_rec, num_planes, x_pix, y_pix = np.shape(stack)\n",
    "        exp_list = glob(str(f / \"behavior/*.json\"))\n",
    "        reg_list = [make_sensory_regressors(Experiment(exp), sampling=1/3) for exp in exp_list]\n",
    "        baseline_frames = [no_regressor_frames(reg) for reg in reg_list]\n",
    "        print(baseline_frames)\n",
    "        analyze_data_statistics(stack, z_plane=0)\n",
    "        \n",
    "        dff_result = calculate_dff(\n",
    "            stack, \n",
    "            baseline_frames,\n",
    "            percentile_value=1.0,             # Use 1st percentile for min_subtract\n",
    "            timing=True                       # Show timing information\n",
    "        )\n",
    "        \n",
    "        for i in range(num_planes):\n",
    "    \n",
    "            if i < 10:\n",
    "                file_name = '000' + str(i) + '.h5'\n",
    "            else:\n",
    "                file_name = '00' + str(i) + '.h5'\n",
    "\n",
    "            data_out = dff_result[:,i,:,:]\n",
    "            data_out = np.expand_dims(data_out, 1)\n",
    "\n",
    "            dff_dir = (f / \"dff2\")\n",
    "            dff_dir.mkdir(exist_ok=True)\n",
    "            data_out_folder = str(f / \"dff2\" / file_name)\n",
    "            fl.save(data_out_folder, {\"stack_4D\": data_out}, compression=\"blosc\")\n",
    "            \n",
    "        shutil.copy(str(f / \"aligned/stack_metadata.json\"), str(f / \"dff2\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
