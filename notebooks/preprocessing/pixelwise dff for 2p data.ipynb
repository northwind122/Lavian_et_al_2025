{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "275924a0-2ee0-45cd-9562-b44f54beaeb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T17:53:41.734734Z",
     "iopub.status.busy": "2026-01-27T17:53:41.734149Z",
     "iopub.status.idle": "2026-01-27T17:53:41.760215Z",
     "shell.execute_reply": "2026-01-27T17:53:41.759375Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a964f75-329b-4742-a19b-5405fe5d79ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T17:53:41.763589Z",
     "iopub.status.busy": "2026-01-27T17:53:41.763328Z",
     "iopub.status.idle": "2026-01-27T17:53:42.461784Z",
     "shell.execute_reply": "2026-01-27T17:53:42.461302Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import flammkuchen as fl\n",
    "import json\n",
    "\n",
    "from split_dataset import SplitDataset\n",
    "%autoreload\n",
    "from glob import glob\n",
    "from bouter import Experiment\n",
    "\n",
    "from lavian_et_al_2025.visual_motion.stimulus_functions import make_sensory_regressors\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import convolve2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6693c41c-1b35-4bea-a8f6-23806826acb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T17:53:42.464996Z",
     "iopub.status.busy": "2026-01-27T17:53:42.464812Z",
     "iopub.status.idle": "2026-01-27T17:53:42.467425Z",
     "shell.execute_reply": "2026-01-27T17:53:42.467041Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import warnings\n",
    "from typing import List, Union, Tuple\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e8a3992-6df3-420b-b938-c071e7d91340",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T17:53:42.469842Z",
     "iopub.status.busy": "2026-01-27T17:53:42.469716Z",
     "iopub.status.idle": "2026-01-27T17:53:42.477156Z",
     "shell.execute_reply": "2026-01-27T17:53:42.476721Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_dff(\n",
    "    stack: np.ndarray,\n",
    "    baseline_frames,\n",
    "    min_baseline_value=1.0,\n",
    "    percentile_value=1.0,\n",
    "    global_offset=None,\n",
    "    timing=True\n",
    "    ): \n",
    "    \"\"\"\n",
    "    Calculate ΔF/F for a 4D calcium imaging stack with offset correction.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    stack : np.ndarray\n",
    "        4D array with dimensions (time, z, x, y)\n",
    "    baseline_frames : Union[List[int], np.ndarray, List[List[int]]]\n",
    "        Frame indices for baseline calculation.\n",
    "        If per_plane_baselines=True, should be a list with baseline frames for each z-plane.\n",
    "    min_baseline_value : float, optional\n",
    "        Minimum value for the baseline, by default 1.0\n",
    "    percentile_value : float, optional\n",
    "        Percentile to use for 'min_subtract' method (1.0 = 1st percentile), by default 1.0\n",
    "    global_offset : float, optional\n",
    "        Manual offset value to add if offset_correction='manual', by default None\n",
    "        Whether to handle NaN values in the data, by default True\n",
    "    timing : bool, optional\n",
    "        Whether to print timing information, by default True\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        4D array with ΔF/F values\n",
    "    \"\"\"\n",
    "    if timing:\n",
    "        start_time = time.time()\n",
    "    \n",
    "    # Convert to float if needed\n",
    "    if not np.issubdtype(stack.dtype, np.floating):\n",
    "        stack = stack.astype(np.float32)\n",
    "        if timing:\n",
    "            print(f\"Data type conversion: {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    # Get dimensions\n",
    "    t_max, z_max, x_max, y_max = stack.shape\n",
    "    \n",
    "    # Create a mask for NaN values in the original stack (to preserve them)\n",
    "    original_nan_mask = np.isnan(stack)\n",
    "    if timing and np.any(original_nan_mask):\n",
    "        print(f\"NaN values detected in input: {np.sum(original_nan_mask)} out of {stack.size} elements\")\n",
    "    \n",
    "    # Apply offset correction\n",
    "    if timing:\n",
    "        offset_start = time.time()\n",
    "    \n",
    "    # Replace NaNs with zeros for calculation purposes\n",
    "    corrected_stack = np.nan_to_num(stack, nan=0.0)\n",
    "    \n",
    "    # For each z-plane, find minimum (or low percentile) value and subtract\n",
    "    for z in range(z_max):\n",
    "        min_value = np.nanpercentile(stack[:, z, :, :], percentile_value)\n",
    "        corrected_stack[:, z, :, :] -= min_value\n",
    "        if timing:\n",
    "            print(f\"Z-plane {z}: Subtracted {min_value:.2f} (percentile {percentile_value})\")\n",
    "\n",
    "    if timing:\n",
    "        print(f\"Offset correction: {time.time() - offset_start:.2f} seconds\")\n",
    "        baseline_start = time.time()\n",
    "    \n",
    "    # Initialize result array\n",
    "    dff = np.zeros_like(corrected_stack)\n",
    "    \n",
    "    # Calculate ΔF/F stack\n",
    "    for z in range(z_max):\n",
    "        # Get baseline frames\n",
    "        plane_frames = np.array(baseline_frames[z], dtype=int).flatten()\n",
    "\n",
    "        # Calculate baseline\n",
    "        f0_plane = np.nanmean(stack[plane_frames, z, :, :], axis=0)\n",
    "        # Replace any remaining NaNs in baseline with min_baseline_value\n",
    "        f0_plane = np.nan_to_num(f0_plane, nan=min_baseline_value)\n",
    "\n",
    "        # Apply minimum threshold\n",
    "        f0_plane = np.maximum(f0_plane, min_baseline_value)\n",
    "\n",
    "        # Calculate ΔF/F\n",
    "        dff[:, z, :, :] = (corrected_stack[:, z, :, :] - f0_plane) / f0_plane\n",
    "\n",
    "    \n",
    "    # Restore original NaN values\n",
    "    if np.any(original_nan_mask):\n",
    "        dff[original_nan_mask] = np.nan\n",
    "    \n",
    "    if timing:\n",
    "        total_time = time.time() - start_time\n",
    "        baseline_time = time.time() - baseline_start\n",
    "        print(f\"Baseline calculation: {baseline_time:.2f} seconds\")\n",
    "        print(f\"Total ΔF/F calculation: {total_time:.2f} seconds\")\n",
    "    \n",
    "    return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbc243bc-9637-4a16-9975-414d02e2823f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T17:53:42.479779Z",
     "iopub.status.busy": "2026-01-27T17:53:42.479631Z",
     "iopub.status.idle": "2026-01-27T17:53:42.482331Z",
     "shell.execute_reply": "2026-01-27T17:53:42.481962Z"
    }
   },
   "outputs": [],
   "source": [
    "# find the frames to calculate the baseline.\n",
    "def no_regressor_frames(regressors, threshold=0.05):\n",
    "    return np.where(np.all(regressors < threshold, axis=0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14570cf6-3bce-4ab8-96f6-4cc04ffb72c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T17:53:42.484563Z",
     "iopub.status.busy": "2026-01-27T17:53:42.484445Z",
     "iopub.status.idle": "2026-01-27T17:53:42.487128Z",
     "shell.execute_reply": "2026-01-27T17:53:42.486704Z"
    }
   },
   "outputs": [],
   "source": [
    "master = Path(r\"/mnt/b4b63ff6-d9bf-4a97-9404-ce61fe415540/Home-Appliances/zenodo/Lavian_et_al_2025/data\")\n",
    "all_fish = [\n",
    "    f for f in master.rglob(\"*_f*\")\n",
    "    if (f / \"aligned\").exists()\n",
    "    and (any((f / \"aligned\").glob(\"*stack_metadata.json\")) or any((f / \"aligned\").glob(\"*.h5\")))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d1ea42d-b96f-4ade-8f61-9db6796800c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T17:53:42.489466Z",
     "iopub.status.busy": "2026-01-27T17:53:42.489337Z",
     "iopub.status.idle": "2026-01-27T17:53:42.494066Z",
     "shell.execute_reply": "2026-01-27T17:53:42.493647Z"
    }
   },
   "outputs": [],
   "source": [
    "for f in all_fish:\n",
    "    print(f)\n",
    "    if not (f / \"dff\").exists():\n",
    "        \n",
    "        stack = SplitDataset(f / \"aligned\")[:,:,:,:]\n",
    "        len_rec, num_planes, x_pix, y_pix = np.shape(stack)\n",
    "        exp_list = glob(str(f / \"behavior/*.json\"))\n",
    "        reg_list = [make_sensory_regressors(Experiment(exp), sampling=1/3) for exp in exp_list]\n",
    "        baseline_frames = [no_regressor_frames(reg) for reg in reg_list]\n",
    "        \n",
    "        dff_result = calculate_dff(\n",
    "            stack, \n",
    "            baseline_frames,\n",
    "            percentile_value=1.0,             \n",
    "            timing=True                       \n",
    "        )\n",
    "        \n",
    "        for i in range(num_planes):\n",
    "    \n",
    "            if i < 10:\n",
    "                file_name = '000' + str(i) + '.h5'\n",
    "            else:\n",
    "                file_name = '00' + str(i) + '.h5'\n",
    "\n",
    "            data_out = dff_result[:,i,:,:]\n",
    "            data_out = np.expand_dims(data_out, 1)\n",
    "\n",
    "            dff_dir = (f / \"dff\")\n",
    "            dff_dir.mkdir(exist_ok=True)\n",
    "            data_out_folder = str(f / \"dff\" / file_name)\n",
    "            fl.save(data_out_folder, {\"stack_4D\": data_out}, compression=\"blosc\")\n",
    "            \n",
    "        shutil.copy(str(f / \"aligned/stack_metadata.json\"), str(f / \"dff\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
