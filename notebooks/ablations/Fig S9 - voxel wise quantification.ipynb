{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0662b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bf36aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import flammkuchen as fl\n",
    "from split_dataset import SplitDataset\n",
    "from scipy import stats\n",
    "import colorspacious\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from vision_and_navigation.imaging.general import corr2_coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136c6d7f",
   "metadata": {},
   "source": [
    "# Set fish path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0dc02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = 'ntr' #'control' #'ntr'\n",
    "\n",
    "master = Path(r'\\\\portulab.synology.me\\data\\Hagar and Ot\\E0040\\v10\\LS ablation\\{}'.format(treatment))\n",
    "fish_list = list(master.glob(\"*_f*_{}*\".format(treatment)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d2f5f3",
   "metadata": {},
   "source": [
    "# Load morphed coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a469420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    coords_pooled = fl.load(master / 'coords_pooled_{}.h5'.format(treatment))\n",
    "    in_brain_arr_pooled = fl.load(master / 'in_brain_arr_pooled_{}.h5'.format(treatment))\n",
    "    \n",
    "except OSError:\n",
    "    coords_pooled = {}\n",
    "    in_brain_arr_pooled = {}\n",
    "\n",
    "    for session in ['pre', 'post']:\n",
    "        \n",
    "        session_list = list(master.glob(\"*{}\".format(session)))\n",
    "        morphed_coords = {}\n",
    "        in_brain_arr = {}\n",
    "        \n",
    "        for fish in session_list:\n",
    "            print(fish)\n",
    "\n",
    "            #Load morphed coords\n",
    "            morphed_coords[fish.name] = fl.load(fish / 'registration' / 'to_h2b_baier_ref' / 'antspy' / 'mov_coords_transformed.h5')\n",
    "\n",
    "            #I guess this is an index to keep track of ROIs inside brain? Will make it into a boolean because makes more sense\n",
    "            suite2p_brain = fl.load(fish / \"data_from_suite2p_cells_brain.h5\")\n",
    "\n",
    "            in_brain_arr[fish.name] = np.full(morphed_coords[fish.name].shape[0], False)\n",
    "            in_brain_arr[fish.name][suite2p_brain['coords_idx']] = True\n",
    "\n",
    "        #And pool in a single array\n",
    "        coords_pooled[session] = np.concatenate([morphed_coords[fish.name] for fish in session_list], 0)\n",
    "        in_brain_arr_pooled[session] = np.concatenate([in_brain_arr[fish.name] for fish in session_list])\n",
    "\n",
    "    fl.save(master / 'coords_pooled_{}.h5'.format(treatment), coords_pooled)\n",
    "    fl.save(master / 'in_brain_arr_pooled_{}.h5'.format(treatment), in_brain_arr_pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4be8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_list = list(master.glob(\"*pre\"))\n",
    "\n",
    "for fish in session_list:\n",
    "    print(fish)\n",
    "    suite2p_brain = fl.load(fish / \"data_from_suite2p_cells_brain.h5\")\n",
    "    print(len(suite2p_brain['coords_idx']))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1160106",
   "metadata": {},
   "source": [
    "# Load tuning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09250f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_pooled = {}\n",
    "angle_pooled = {}\n",
    "\n",
    "for session in ['pre', 'post']:\n",
    "    tuning_arrs = fl.load(master / 'tuning_arrs_{}_{}.h5'.format(treatment, session))\n",
    "    amp_pooled[session], angle_pooled[session] = tuning_arrs['amp_pooled'], tuning_arrs['angle_pooled']\n",
    "    \n",
    "    for dicti in [amp_pooled, angle_pooled]:\n",
    "        dicti[session] = np.concatenate([dicti[session][k] for k in list(dicti[session].keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b399b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_arr_pooled = {}\n",
    "\n",
    "for session in ['pre', 'post']:\n",
    "\n",
    "    session_list = list(master.glob(\"*{}\".format(session)))\n",
    "    rel_arr_pooled[session] = np.concatenate([fl.load(fish / \"reliability_index_arr.h5\", \"/reliability_arr_combined\") for fish in session_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea34291",
   "metadata": {},
   "source": [
    "# Load correlation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0cf1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dirs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in ['pre', 'post']:\n",
    "    try:\n",
    "        corrcoefs_all = fl.load(master / 'reg_corrcoefs_pooled_{}_{}_all.h5'.format(treatment, session))\n",
    "\n",
    "    except OSError:\n",
    "        session_list = list(master.glob(\"*{}\".format(session)))\n",
    "\n",
    "        corrcoefs_all = {direction:[] for direction in range(n_dirs)}\n",
    "        \n",
    "        for path in session_list:\n",
    "            traces = fl.load(path / \"filtered_traces.h5\", \"/detr\")\n",
    "            sensory_regressors = fl.load(path / \"sensory_regressors.h5\", \"/regressors\")\n",
    "            \n",
    "            for direction in range(n_dirs):\n",
    "                current_dir = np.asarray(sensory_regressors.iloc[:, direction])        \n",
    "                corrcoefs_all[direction].append(corr2_coeff(traces.T, current_dir.reshape(1, -1)).ravel())\n",
    "                \n",
    "        for direction in range(n_dirs):\n",
    "            corrcoefs_all[direction] = np.concatenate(corrcoefs_all[direction])\n",
    "\n",
    "        fl.save(master / 'reg_corrcoefs_pooled_{}_{}_all.h5'.format(treatment, session), corrcoefs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feee7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_corrcoefs = {}\n",
    "\n",
    "for session in ['pre', 'post']:\n",
    "    session_corrcoefs[session] = fl.load(master / 'reg_corrcoefs_pooled_{}_{}_all.h5'.format(treatment, session))\n",
    "    \n",
    "    full_mat = np.stack([session_corrcoefs[session][direction] for direction in range(n_dirs)])\n",
    "    session_corrcoefs[session] = np.array([full_mat[i, j] for i,j in zip(np.abs(full_mat).argmax(0), np.arange(full_mat.shape[1]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba0f824",
   "metadata": {},
   "source": [
    "## Voxelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6efee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numba\n",
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacc7f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import reference anatomy [from first fish]\n",
    "ref_anatomy = fl.load(fish_list[0] / 'registration' / 'to_h2b_baier_ref' / 'antspy' / 'ref_mapped.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad73dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Safety check\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(ref_anatomy)\n",
    "viewer.add_points(coords_pooled['pre'][in_brain_arr_pooled['pre']], face_color='red')\n",
    "viewer.add_points(coords_pooled['post'][in_brain_arr_pooled['post']], face_color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14db49ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ref_anatomy.shape)\n",
    "print(coords_pooled['pre'].max(0))\n",
    "print(coords_pooled['post'].max(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6452584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define voxel size and define shape of each new anatomical axis\n",
    "vox_size = 5\n",
    "xvx, yvx, zvx = [np.arange(0, ref_anatomy.shape[i], vox_size) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78951704",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def get_voxel_centroids(xvx, yvx, zvx, vox_size):\n",
    "    vx_centroids = np.zeros((xvx.shape[0], yvx.shape[0], zvx.shape[0], 3))\n",
    "\n",
    "    for ix, x in enumerate(xvx):\n",
    "        for iy, y in enumerate(yvx):\n",
    "            for iz, z in enumerate(zvx):\n",
    "                vx_centroids[ix, iy, iz, :] = np.array((x+(vox_size/2),  y+(vox_size/2),  z+(vox_size/2)))\n",
    "    return(vx_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdcc413",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def assign_to_voxels(coords, vx_centroids, vox_size):\n",
    "    coord_vox = np.full_like(coords, np.nan, dtype=numba.int32)\n",
    "\n",
    "    for roi in range(coords.shape[0]):\n",
    "    \n",
    "        a = np.nonzero(np.sum(np.abs(vx_centroids - coords[roi, :]) < (vox_size/2), axis=-1) == 3)\n",
    "        \n",
    "        for i, coord in enumerate(a):\n",
    "            coord_vox[roi, i] = coord[0]\n",
    "        \n",
    "    return(coord_vox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543abf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    voxeled_rois = fl.load(master / 'voxeled_rois_{}_{}voxsize.h5'.format(treatment, vox_size))\n",
    "\n",
    "except OSError:\n",
    "     \n",
    "    voxeled_rois = {}\n",
    "    \n",
    "    for session in ['pre', 'post']:\n",
    "        vx_centroids = get_voxel_centroids(xvx, yvx, zvx, vox_size)\n",
    "        voxeled_rois[session] = assign_to_voxels(coords_pooled[session], vx_centroids, vox_size)\n",
    "        \n",
    "    fl.save(master / 'voxeled_rois_{}_{}voxsize.h5'.format(treatment, vox_size), voxeled_rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4556bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_map = {}\n",
    "\n",
    "for session in ['pre', 'post']:\n",
    "    occ_map[session] = np.full((xvx.shape[0], yvx.shape[0], zvx.shape[0]), np.nan)\n",
    "    coords = voxeled_rois[session][in_brain_arr_pooled[session]]\n",
    "\n",
    "    unique_coords, counts = np.unique(coords, axis=0, return_counts=True)\n",
    "    for coord, count in zip(unique_coords, counts):\n",
    "        occ_map[session][tuple(coord)] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb8180",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(occ_map['pre'], colormap='Reds')\n",
    "viewer.add_image(occ_map['post'], colormap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523ab3ad",
   "metadata": {},
   "source": [
    "# Alright let's make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7926a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jit(nopython=True)\n",
    "# def make_map_from_values(vxv, yvx, zvx, coords, metric_arr):\n",
    "#     map_arr = np.full((xvx.shape[0], yvx.shape[0], zvx.shape[0]), np.nan)\n",
    "#     unique_coords = np.unique(coords, axis=0)\n",
    "    \n",
    "#     for coord in unique_coords:\n",
    "#         vox_rois = np.argwhere(((coords == coord).all(axis=1)))\n",
    "#         rel_map[tuple(coord)] = np.mean(metric_arr[vox_rois])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42053c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reliability map\n",
    "try:\n",
    "    rel_map = fl.load(master / 'rel_map_{}_{}voxsize.h5'.format(treatment, vox_size))\n",
    "    \n",
    "except OSError:    \n",
    "    rel_map = {}\n",
    "\n",
    "    for session in ['pre', 'post']:\n",
    "        rel_map[session] = np.full((xvx.shape[0], yvx.shape[0], zvx.shape[0]), np.nan)\n",
    "        coords = voxeled_rois[session][in_brain_arr_pooled[session]]\n",
    "\n",
    "        unique_coords = np.unique(coords, axis=0)\n",
    "\n",
    "        for coord in unique_coords:\n",
    "            vox_rois = np.argwhere(((coords == coord).all(axis=1)))\n",
    "            rel_map[session][tuple(coord)] = np.mean(rel_arr_pooled[session][vox_rois])\n",
    "\n",
    "    fl.save(master / 'rel_map_{}_{}voxsize.h5'.format(treatment, vox_size), rel_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc503e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amplitude map\n",
    "try:\n",
    "    amp_map = fl.load(master / 'amp_map_{}_{}voxsize.h5'.format(treatment, vox_size))\n",
    "    \n",
    "except OSError:    \n",
    "    amp_map = {}\n",
    "\n",
    "    for session in ['pre', 'post']:\n",
    "        amp_map[session] = np.full((xvx.shape[0], yvx.shape[0], zvx.shape[0]), np.nan)\n",
    "        coords = voxeled_rois[session][in_brain_arr_pooled[session]]\n",
    "\n",
    "        unique_coords = np.unique(coords, axis=0)\n",
    "\n",
    "        for coord in unique_coords:\n",
    "            vox_rois = np.argwhere(((coords == coord).all(axis=1)))\n",
    "            amp_map[session][tuple(coord)] = np.mean(amp_pooled[session][in_brain_arr_pooled[session]][vox_rois])\n",
    "\n",
    "    fl.save(master / 'amp_map_{}_{}voxsize.h5'.format(treatment, vox_size), amp_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d12b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation map\n",
    "try:\n",
    "    corr_map = fl.load(master / 'corr_map_{}_{}voxsize.h5'.format(treatment, vox_size))\n",
    "\n",
    "except OSError:    \n",
    "    corr_map = {}\n",
    "\n",
    "    for session in ['pre', 'post']:\n",
    "        corr_map[session] = np.full((xvx.shape[0], yvx.shape[0], zvx.shape[0]), np.nan)\n",
    "        coords = voxeled_rois[session][in_brain_arr_pooled[session]]\n",
    "\n",
    "        unique_coords = np.unique(coords, axis=0)\n",
    "\n",
    "        for coord in unique_coords:\n",
    "            vox_rois = np.argwhere(((coords == coord).all(axis=1)))\n",
    "            corr_map[session][tuple(coord)] = np.nanmean(session_corrcoefs[session][in_brain_arr_pooled[session]][vox_rois])\n",
    "            \n",
    "    fl.save(master / 'corr_map_{}_{}voxsize.h5'.format(treatment, vox_size), corr_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924a8004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_stack(z_size, n_planes):\n",
    "    step_size = z_size//n_planes\n",
    "    z_levels = np.arange(0, z_size, step_size)\n",
    "    z_levels = np.append(z_levels, z_size)\n",
    "    \n",
    "    return z_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c3fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a2faeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_planes = 3\n",
    "\n",
    "rel_cmap = 'Reds'\n",
    "rel_vlims = [0,1]\n",
    "diff_cmap = 'RdBu_r'\n",
    "diff_vlims = [-.5, .5]\n",
    "\n",
    "\n",
    "z_levels = slice_stack(rel_map['pre'].shape[2], n_planes)\n",
    "\n",
    "fig, axes = plt.subplots(n_planes, 3, figsize=(6, 8))\n",
    "\n",
    "for i_session, session in enumerate(['pre', 'post']):\n",
    "    session_map = rel_map[session]\n",
    "\n",
    "    for plane in range(n_planes):\n",
    "        map_slice = session_map[:, :, z_levels[plane]:z_levels[plane+1]]\n",
    "        axes[n_planes-1-plane, i_session].imshow(np.nanmean(map_slice, 2).T, cmap=rel_cmap, vmin=rel_vlims[0], vmax=rel_vlims[1])\n",
    "\n",
    "    axes[0, i_session].set_title(session)\n",
    "    \n",
    "diff_map = rel_map['post']-rel_map['pre']\n",
    "for plane in range(n_planes):\n",
    "    map_slice = diff_map[:, :, z_levels[plane]:z_levels[plane+1]]\n",
    "    axes[n_planes-1-plane, 2].imshow(np.nanmean(map_slice, 2).T, cmap=diff_cmap, vmin=diff_vlims[0], vmax=diff_vlims[1])\n",
    "axes[0, 2].set_title('post - pre')\n",
    "    \n",
    "for ax in axes.ravel():\n",
    "    ax.axis('off')\n",
    "\n",
    "divider = make_axes_locatable(axes[-1, 0])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "cmap = mpl.cm.cool\n",
    "norm = mpl.colors.Normalize(vmin=rel_vlims[0], vmax=rel_vlims[1])\n",
    "fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=rel_cmap), cax=cax, fraction=.5)\n",
    "    \n",
    "divider = make_axes_locatable(axes[-1, 2])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "cmap = mpl.cm.cool\n",
    "norm = mpl.colors.Normalize(vmin=diff_vlims[0], vmax=diff_vlims[1])\n",
    "fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=diff_cmap), cax=cax, fraction=.5)\n",
    "    \n",
    "plt.suptitle('Reliability ({})'.format(treatment))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c05b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fig_path is not None:\n",
    "    fig.savefig(fig_path / 'reliability_voxelwise_{}_{}voxsize.pdf'.format(treatment, vox_size), dpi=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_planes = 3\n",
    "\n",
    "rel_cmap = 'Reds'\n",
    "rel_vlims = [0, 1300]\n",
    "diff_cmap = 'RdBu_r'\n",
    "diff_vlims = [-1000, 1000]\n",
    "\n",
    "\n",
    "z_levels = slice_stack(rel_map['pre'].shape[2], n_planes)\n",
    "\n",
    "fig, axes = plt.subplots(n_planes, 3, figsize=(6, 8))\n",
    "\n",
    "for i_session, session in enumerate(['pre', 'post']):\n",
    "    session_map = amp_map[session]\n",
    "\n",
    "    for plane in range(n_planes):\n",
    "        map_slice = session_map[:, :, z_levels[plane]:z_levels[plane+1]]\n",
    "        axes[n_planes-1-plane, i_session].imshow(np.nanmean(map_slice, 2).T, cmap=rel_cmap, vmin=rel_vlims[0], vmax=rel_vlims[1])\n",
    "\n",
    "    axes[0, i_session].set_title(session)\n",
    "    \n",
    "diff_map = amp_map['post']-amp_map['pre']\n",
    "for plane in range(n_planes):\n",
    "    map_slice = diff_map[:, :, z_levels[plane]:z_levels[plane+1]]\n",
    "    axes[n_planes-1-plane, 2].imshow(np.nanmean(map_slice, 2).T, cmap=diff_cmap, vmin=diff_vlims[0], vmax=diff_vlims[1])\n",
    "axes[0, 2].set_title('post - pre')\n",
    "    \n",
    "for ax in axes.ravel():\n",
    "    ax.axis('off')\n",
    "    \n",
    "\n",
    "divider = make_axes_locatable(axes[-1, 0])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "cmap = mpl.cm.cool\n",
    "norm = mpl.colors.Normalize(vmin=rel_vlims[0], vmax=rel_vlims[1])\n",
    "fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=rel_cmap), cax=cax, fraction=.5)\n",
    "    \n",
    "divider = make_axes_locatable(axes[-1, 2])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "cmap = mpl.cm.cool\n",
    "norm = mpl.colors.Normalize(vmin=diff_vlims[0], vmax=diff_vlims[1])\n",
    "fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=diff_cmap), cax=cax, fraction=.5)\n",
    "    \n",
    "plt.suptitle('Amplitude ({})'.format(treatment))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f29495",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fig_path is not None:\n",
    "    fig.savefig(fig_path / 'amplitude_voxelwise_{}_{}voxsize.pdf'.format(treatment, vox_size), dpi=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cb9093",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_planes = 3\n",
    "\n",
    "corr_cmap = 'RdBu_r'\n",
    "corr_vlims = [-.5, .5]\n",
    "diff_cmap = 'RdBu_r'\n",
    "diff_vlims = [-.5, .5]\n",
    "\n",
    "z_levels = slice_stack(corr_map['pre'].shape[2], n_planes)\n",
    "\n",
    "fig, axes = plt.subplots(n_planes, 3, figsize=(6, 8))\n",
    "\n",
    "for i_session, session in enumerate(['pre', 'post']):\n",
    "    session_map = corr_map[session]\n",
    "\n",
    "    for plane in range(n_planes):\n",
    "        map_slice = session_map[:, :, z_levels[plane]:z_levels[plane+1]]\n",
    "        axes[n_planes-1-plane, i_session].imshow(np.nanmean(map_slice, 2).T, cmap=corr_cmap, vmin=corr_vlims[0], vmax=corr_vlims[1])\n",
    "\n",
    "    axes[0, i_session].set_title(session)\n",
    "    \n",
    "diff_map = corr_map['post']-corr_map['pre']\n",
    "for plane in range(n_planes):\n",
    "    map_slice = diff_map[:, :, z_levels[plane]:z_levels[plane+1]]\n",
    "    axes[n_planes-1-plane, 2].imshow(np.nanmean(map_slice, 2).T, cmap=diff_cmap, vmin=diff_vlims[0], vmax=diff_vlims[1])\n",
    "axes[0, 2].set_title('post - pre')\n",
    "    \n",
    "for ax in axes.ravel():\n",
    "    ax.axis('off')\n",
    "    \n",
    "\n",
    "divider = make_axes_locatable(axes[-1, 0])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "cmap = mpl.cm.cool\n",
    "norm = mpl.colors.Normalize(vmin=corr_vlims[0], vmax=corr_vlims[1])\n",
    "fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=corr_cmap), cax=cax, fraction=.5)\n",
    "    \n",
    "divider = make_axes_locatable(axes[-1, 2])\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "cmap = mpl.cm.cool\n",
    "norm = mpl.colors.Normalize(vmin=diff_vlims[0], vmax=diff_vlims[1])\n",
    "fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=diff_cmap), cax=cax, fraction=.5)\n",
    "    \n",
    "# plt.suptitle('Amplitude ({})'.format(treatment))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3787f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fig_path is not None:\n",
    "    fig.savefig(fig_path / 'corrcoef_voxelwise_{}_{}voxsize.pdf'.format(treatment, vox_size), dpi=350)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
